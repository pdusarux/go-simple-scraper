# Go Simple Web Crawler

This project is a simple web crawler written in Go that can concurrently find URLs from specified web pages.

## Features

- Searches for URLs from specified web pages
- Works concurrently using goroutines and channels
- Displays a list of all found URLs

## Installation

1. Make sure you have Go installed on your machine
2. Clone this repository:
   ```
   git clone https://github.com/pdusarux/go-simple-scraper.git
   ```
3. Navigate to the project folder:
   ```
   cd go-simple-scraper
   ```
4. Install dependencies:
   ```
   go mod download
   ```

## Usage

Run the program by specifying the URLs you want to crawl as arguments:

## Credits

This project was created by [Akhil Sharma](https://www.youtube.com/@AkhilSharmaTech). Special thanks to Akhil Sharma for the guidance in building a scraper without using any library.

- YouTube Channel: [Akhil Sharma](https://www.youtube.com/@AkhilSharmaTech)
- Video: [[Complete] simple golang scraper - no library](https://youtube.com/playlist?list=PL5dTjWUk_cPY68ZnWuybvmlcI-DgzYgFA&si=E_SEbcSghW5ffq-n)
